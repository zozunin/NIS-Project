{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96232984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheot\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\"\"\"import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\"\"\"\n",
    "from PIL import Image\n",
    "import io\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from functools import reduce\n",
    "import os\n",
    "from scipy.spatial.distance import cosine\n",
    "import pickle\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8640e1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cvx in c:\\users\\sheot\\anaconda3\\lib\\site-packages (0.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\sheot\\appdata\\roaming\\python\\python38\\site-packages (from cvx) (1.22.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install cvx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f6655aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_hash_img(pth):\n",
    "    from PIL import Image\n",
    "    with Image.open(pth) as img:\n",
    "        img = img.resize((10,10), Image.ANTIALIAS).convert(\"1\") #shrink and reduce colors\n",
    "        pixel_data = list(img.getdata())\n",
    "        avg_pixel = sum(pixel_data)/len(pixel_data)\n",
    "        bits = \"\".join(['1' if (px >= avg_pixel) else '0' for px in pixel_data])\n",
    "        hex_representation = str(hex(int(bits, 2)))[2:][::-1].upper()\n",
    "        return hex_representation\n",
    "    \n",
    "def use_pkl(mode, pkl_path, file_to_pkl = None):\n",
    "    if not mode == 'rb' and not mode == 'ab' and not mode == 'wb':\n",
    "        return None\n",
    "    with open(pkl_path, mode) as f:\n",
    "        if mode == 'rb':\n",
    "            res = pickle.load(f)\n",
    "            assert type(res) == np.ndarray or type(res) == pd.DataFrame\n",
    "            res_add = []\n",
    "            while True:\n",
    "                try:\n",
    "                    res_add.append(pickle.load(f))\n",
    "                except EOFError:\n",
    "                    break\n",
    "            if type(res) == np.ndarray:\n",
    "                return np.concatenate([res, *res_add], axis = 0)\n",
    "            else:\n",
    "                return pd.concat([res, *res_add], axis=0)\n",
    "        else:\n",
    "            pickle.dump(file_to_pkl, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bfadee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_df = use_pkl('rb', 'models_by_dim/embeddings.pkl')\n",
    "hashtag_features = use_pkl('rb', 'models_by_dim/hashtags.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "54e4100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_image(img_path, dims = (224, 224, 3), where='local'):\n",
    "    height, width, _ = dims\n",
    "    if not where == 'local':\n",
    "        return\n",
    "    img = tf.cast(tf.image.decode_image(tf.io.read_file(img_path)), tf.float32)\n",
    "    img = (img/127.5) - 1 #normalize\n",
    "    img = tf.image.resize(img, (height, width))\n",
    "    if img.shape != dims: #for grayscale\n",
    "        img = tf.concat([img, img, img], axis=2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def extract_features(image, nn):\n",
    "    image_np = image.numpy()\n",
    "    images_np = np.expand_dims(image_np, axis=0)\n",
    "    deep_features = nn.predict(images_np)[0]\n",
    "    return deep_features\n",
    "\n",
    "def prepare_img(image_path, where='local'):\n",
    "    prep_image = prepare_image(image_path, where='local')\n",
    "    pic = pca_model.transform(extract_features(prep_image, neural_network).reshape(1,-1)).reshape(-1)\n",
    "    return pic\n",
    "\n",
    "def find_neighbor_vectors(pic, k=5, recommender_df=recommender_df):\n",
    "    \"\"\"Find image features (user vectors) for similar images.\"\"\"\n",
    "    rdf = recommender_df.copy()\n",
    "    rdf['dist'] = rdf['deep_features'].apply(lambda x: cosine(x, pic))\n",
    "    rdf = rdf.sort_values(by='dist')\n",
    "    return rdf.head(k)\n",
    "\n",
    "def generate_hashtags(pic, return_uf = False, min_recs = 10):\n",
    "    fnv = find_neighbor_vectors(pic, k=5, recommender_df=recommender_df)\n",
    "    # Find the average of the 5 user features found based on cosine similarity.\n",
    "    features = []\n",
    "    for item in fnv.features.values:\n",
    "        features.append(item)\n",
    "\n",
    "    avg_features = np.mean(np.asarray(features), axis=0)\n",
    "    \n",
    "    # Add new column to the hashtag features which will be the dot product with the average image(user) features\n",
    "    hashtag_features['dot_product'] = hashtag_features['features'].apply(lambda x: np.asarray(x).dot(avg_features))\n",
    "\n",
    "    # Find the 10 hashtags with the highest feature dot products\n",
    "    final_recs = hashtag_features.sort_values(by='dot_product', ascending=False).head(min_recs)\n",
    "    #print(final_recs)\n",
    "    # Look up hashtags by their numeric IDs\n",
    "    if not return_uf:\n",
    "        avg_features = None\n",
    "    return final_recs['tag'].to_list(), avg_features\n",
    "\n",
    "def get_results(path_to_pic, add_to_model = False, new_ind = None):\n",
    "    \n",
    "    \"\"\"Need to load embeddings.pkl to recommender_df, hashtags.pkl to hashtag_features for this to work\"\"\"\n",
    "    \n",
    "    im_hash = avg_hash_img(path_to_pic)\n",
    "    \n",
    "    in_db = sum(recommender_df['image_hash'].isin([im_hash]))\n",
    "    \n",
    "    if in_db:\n",
    "        \n",
    "        target_pic = recommender_df[recommender_df['image_hash'] == im_hash]\n",
    "        \n",
    "        embedding = target_pic['deep_features'].values[0]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        embedding = prepare_img(path_to_pic)\n",
    "        \n",
    "    tags, user_feat = generate_hashtags(embedding, return_uf = add_to_model)\n",
    "    \n",
    "    if in_db: new_ind = target_pic.index[0]\n",
    "    \n",
    "    elif add_to_model:\n",
    "        \n",
    "        new_ind = max(recommender_df.index) + 1\n",
    "        \n",
    "        props = {'image_hash' : im_hash, 'hashtags' : [tags], \n",
    "                               'deep_features' : [embedding], 'features' : [user_feat]}\n",
    "        \n",
    "        to_pkl = pd.DataFrame(props, index = [new_ind])\n",
    "        \n",
    "        for k,v in props.items():\n",
    "            \n",
    "            recommender_df.loc[new_ind,k] = v[0]\n",
    "            \n",
    "        use_pkl('ab', 'embeddings.pkl', file_to_pkl = to_pkl)\n",
    "        \n",
    "    return tags, new_ind #recommended tags & index of the newly added picture - necessary for uploading new hashtags\n",
    "\n",
    "def add_hashtags_to_db(picture_df_index, str_of_hashtags, vector_len = 50, eps = 1e-2):\n",
    "    \n",
    "    global hashtag_features\n",
    "    \n",
    "    assert picture_df_index in recommender_df.index\n",
    "    \n",
    "    str_of_hashtags = list(set(str_of_hashtags))\n",
    "    \n",
    "    A = [fv for fv in recommender_df['features']]\n",
    "    \n",
    "    props = {'features' : [], 'id' : [], 'tag' : []}\n",
    "    \n",
    "    curr_index = max(hashtag_features.index) + 1\n",
    "    \n",
    "    #dotprod = np.array([f for f in recommender_df.features]) @ np.array([t for t in hashtag_features.features]).T\n",
    "    #max_dotprod = dotprod.max()\n",
    "    #min_dotprod = dotprod.min()\n",
    "    \n",
    "    #A = np.array([f for f in recommender_df.features])\n",
    "    \n",
    "    for hashtag in str_of_hashtags:\n",
    "        \n",
    "        hashtag = '#' + hashtag\n",
    "        \n",
    "        h_index = hashtag_features[hashtag_features['tag'] == hashtag]\n",
    "        \n",
    "        #pics_for_hashtag = h_index['image_id'].values\n",
    "        \n",
    "        if len(h_index) > 0: #hashtag already in database\n",
    "            \n",
    "            h_index = h_index.index[0]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            h_index = None\n",
    "        \n",
    "        A, b = [], [] \n",
    "        \n",
    "        hashtag_vector = cp.Variable((vector_len, ))  \n",
    "        \n",
    "        for index in recommender_df.index:\n",
    "            \n",
    "            if h_index and (index != picture_df_index): #hashtag is not suitable for the pic\n",
    "                \n",
    "                A.append(recommender_df.at[index, 'features'])\n",
    "                b.append(recommender_df.at[index, 'features'] @ hashtag_features.at[h_index, 'features'].T)\n",
    "                \n",
    "        A, b = np.array(A), np.array(b)\n",
    "        \n",
    "        problem = cp.Problem(cp.Maximize(recommender_df.at[picture_df_index, 'features'] @ hashtag_vector), \n",
    "                             [A @ hashtag_vector <= b + 0.01,\n",
    "                             b - 0.01 <= A @ hashtag_vector])\n",
    "        \n",
    "        problem.solve()\n",
    "        \n",
    "        hashtag_vector = hashtag_vector.value\n",
    "        \n",
    "        if hashtag_vector is None: continue\n",
    "        \n",
    "        if h_index:\n",
    "            \n",
    "            hashtag_features.at[h_index, 'features'] = hashtag_vector.T\n",
    "            \n",
    "        else:\n",
    "            props['features'].append(hashtag_vector)\n",
    "            props['tag'].append(hashtag)\n",
    "            props['id'].append(curr_index)\n",
    "            curr_index += 1\n",
    "        \n",
    "    if props['id']:\n",
    "        to_pkl = pd.DataFrame(props, index = props['id'])\n",
    "\n",
    "        hashtag_features = pd.concat([hashtag_features, to_pkl])\n",
    "\n",
    "        use_pkl('ab', 'hashtags.pkl', file_to_pkl = to_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8479f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (224, 224, 3)\n",
    "\n",
    "base_model = MobileNetV2(input_shape=img_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "neural_network = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f28b7219",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_img = r'D:\\fixed_data\\fixed_data\\summer\\_Post Ca1Q3LfhLKM_2022-03-08_06-08-49_UTC.jpg'\n",
    "#path_to_img = r'D:\\fixed_data\\fixed_data\\love\\_Post CcfTC9OrTUl_2022-04-18_10-27-23_UTC_1.jpg'\n",
    "path_to_img = r'D:\\fixed_data\\fixed_data\\tattoo\\_Post CdBwlO2vFa2_2022-05-01_19-39-39_UTC.jpg'\n",
    "recom_tags, new_img_index = get_results(path_to_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "daf768a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#fashion',\n",
       " '#likeforlikes',\n",
       " '#model',\n",
       " '#music',\n",
       " '#happy',\n",
       " '#cute',\n",
       " '#picoftheday',\n",
       " '#beauty',\n",
       " '#style',\n",
       " '#nofilter']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recom_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b71229b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_hashtags = 'model beauty' #пусть пользователь добавляет только в таком виде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "edecb2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_hashtags = usr_hashtags.split()\n",
    "add_hashtags_to_db(new_img_index, usr_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29e4849f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_hash</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>deep_features</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>454AA240948248A444AA459AA</td>\n",
       "      <td>[#photography, #photooftheday, #smile, #fashio...</td>\n",
       "      <td>[5.882194995880127, -0.2370794713497162, 2.885...</td>\n",
       "      <td>[0.32798207, 0.07688697, 0.84293115, 0.2175694...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>AF7BDBB55D4D6B27DC65BACFF</td>\n",
       "      <td>[#love, #art, #foryou, #healthylifestyle, #exp...</td>\n",
       "      <td>[-1.8345609903335571, 2.8283426761627197, 5.58...</td>\n",
       "      <td>[0.4288217, -0.28197622, 0.5414387, 0.3370693,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8523</th>\n",
       "      <td>FFFFFFFFFFFAFBFFFFFFFDFFF</td>\n",
       "      <td>[#foodporn]</td>\n",
       "      <td>[-5.465549468994141, 5.820854187011719, 4.0939...</td>\n",
       "      <td>[-0.0026790556, -0.3919861, -0.04752933, 0.132...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12361</th>\n",
       "      <td>0860539A5844EA4A27B82B4BD</td>\n",
       "      <td>[#instamood]</td>\n",
       "      <td>[3.5241565704345703, 0.36587613821029663, -1.0...</td>\n",
       "      <td>[-0.14015087, 0.013544979, -0.27844265, 0.2826...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7591</th>\n",
       "      <td>80DDEFFF7BFFF7DBEFBC7FEFA</td>\n",
       "      <td>[#fitness, #academia, #fit]</td>\n",
       "      <td>[3.1401686668395996, 1.776392936706543, -1.935...</td>\n",
       "      <td>[-0.26365972, -0.08887135, -0.15122034, 0.1204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>EF20455DABA3FC9F3BA590945</td>\n",
       "      <td>[#life]</td>\n",
       "      <td>[-2.20752215385437, 9.932308197021484, 2.21486...</td>\n",
       "      <td>[-0.26728785, 0.14979428, 0.092606515, 0.02256...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19648</th>\n",
       "      <td>24040441A02413255DFD3BEFF</td>\n",
       "      <td>[#photooftheday, #sports, #instalove, #basketb...</td>\n",
       "      <td>[-8.943175315856934, 6.463971138000488, -0.098...</td>\n",
       "      <td>[0.13210227, 0.41727182, -0.041841343, -0.1275...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>42525A25910B49482845B8671</td>\n",
       "      <td>[#happy]</td>\n",
       "      <td>[6.141420364379883, -1.9803180694580078, 0.050...</td>\n",
       "      <td>[-0.28683725, -0.103673086, -0.15897422, 0.041...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799</th>\n",
       "      <td>5702018040045A40674B5AEEF</td>\n",
       "      <td>[#instadaily]</td>\n",
       "      <td>[3.5415308475494385, -2.96679949760437, 3.5645...</td>\n",
       "      <td>[0.005479329, -0.11904847, -0.07229346, -0.028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>92CB4E4CB0D6C70F275AF9EFB</td>\n",
       "      <td>[#beauty]</td>\n",
       "      <td>[4.016493320465088, 0.8694274425506592, -6.084...</td>\n",
       "      <td>[0.19566903, -0.10315794, -0.03505638, 0.16343...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18220 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         image_hash  \\\n",
       "image_id                              \n",
       "7086      454AA240948248A444AA459AA   \n",
       "1828      AF7BDBB55D4D6B27DC65BACFF   \n",
       "8523      FFFFFFFFFFFAFBFFFFFFFDFFF   \n",
       "12361     0860539A5844EA4A27B82B4BD   \n",
       "7591      80DDEFFF7BFFF7DBEFBC7FEFA   \n",
       "...                             ...   \n",
       "13123     EF20455DABA3FC9F3BA590945   \n",
       "19648     24040441A02413255DFD3BEFF   \n",
       "9845      42525A25910B49482845B8671   \n",
       "10799     5702018040045A40674B5AEEF   \n",
       "2732      92CB4E4CB0D6C70F275AF9EFB   \n",
       "\n",
       "                                                   hashtags  \\\n",
       "image_id                                                      \n",
       "7086      [#photography, #photooftheday, #smile, #fashio...   \n",
       "1828      [#love, #art, #foryou, #healthylifestyle, #exp...   \n",
       "8523                                            [#foodporn]   \n",
       "12361                                          [#instamood]   \n",
       "7591                            [#fitness, #academia, #fit]   \n",
       "...                                                     ...   \n",
       "13123                                               [#life]   \n",
       "19648     [#photooftheday, #sports, #instalove, #basketb...   \n",
       "9845                                               [#happy]   \n",
       "10799                                         [#instadaily]   \n",
       "2732                                              [#beauty]   \n",
       "\n",
       "                                              deep_features  \\\n",
       "image_id                                                      \n",
       "7086      [5.882194995880127, -0.2370794713497162, 2.885...   \n",
       "1828      [-1.8345609903335571, 2.8283426761627197, 5.58...   \n",
       "8523      [-5.465549468994141, 5.820854187011719, 4.0939...   \n",
       "12361     [3.5241565704345703, 0.36587613821029663, -1.0...   \n",
       "7591      [3.1401686668395996, 1.776392936706543, -1.935...   \n",
       "...                                                     ...   \n",
       "13123     [-2.20752215385437, 9.932308197021484, 2.21486...   \n",
       "19648     [-8.943175315856934, 6.463971138000488, -0.098...   \n",
       "9845      [6.141420364379883, -1.9803180694580078, 0.050...   \n",
       "10799     [3.5415308475494385, -2.96679949760437, 3.5645...   \n",
       "2732      [4.016493320465088, 0.8694274425506592, -6.084...   \n",
       "\n",
       "                                                   features  \n",
       "image_id                                                     \n",
       "7086      [0.32798207, 0.07688697, 0.84293115, 0.2175694...  \n",
       "1828      [0.4288217, -0.28197622, 0.5414387, 0.3370693,...  \n",
       "8523      [-0.0026790556, -0.3919861, -0.04752933, 0.132...  \n",
       "12361     [-0.14015087, 0.013544979, -0.27844265, 0.2826...  \n",
       "7591      [-0.26365972, -0.08887135, -0.15122034, 0.1204...  \n",
       "...                                                     ...  \n",
       "13123     [-0.26728785, 0.14979428, 0.092606515, 0.02256...  \n",
       "19648     [0.13210227, 0.41727182, -0.041841343, -0.1275...  \n",
       "9845      [-0.28683725, -0.103673086, -0.15897422, 0.041...  \n",
       "10799     [0.005479329, -0.11904847, -0.07229346, -0.028...  \n",
       "2732      [0.19566903, -0.10315794, -0.03505638, 0.16343...  \n",
       "\n",
       "[18220 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8f4cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_features.drop(index = 1234, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3f54c8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012104370370379428"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender_df.at[new_img_index, 'features'] @ hashtag_features[hashtag_features['tag'] == '#beauty']['features'].to_numpy()[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cb3f5ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02307794236917885"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender_df.at[new_img_index, 'features'] @ hashtag_features[hashtag_features['tag'] == '#model']['features'].to_numpy()[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a0d75ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.94173011e-03,  7.94576675e-03, -1.56590863e-02, -1.58128187e-02,\n",
       "        8.59699248e-04,  1.59424289e-03, -9.70232211e-03,  1.79261321e-04,\n",
       "        2.91500957e-03,  1.16909468e-02,  1.32688194e-02, -2.00407389e-02,\n",
       "       -6.68882306e-03, -1.65787900e-02,  6.61496696e-05, -3.00379792e-03,\n",
       "        8.53128637e-03,  4.28541947e-03,  1.09570143e-02,  1.61566250e-02,\n",
       "       -1.08955094e-02,  1.16876365e-02,  4.90742868e-03,  1.66359474e-02,\n",
       "        2.35087836e-02, -3.51989329e-03,  7.99301737e-03,  8.05896683e-03,\n",
       "       -4.62536580e-03, -2.64432413e-03, -6.56887848e-03, -1.47258760e-03,\n",
       "       -9.77266727e-03, -1.56688933e-03,  2.54001679e-02, -4.63402378e-03,\n",
       "        5.62924561e-03, -8.15451705e-03,  7.67098445e-03,  7.21694107e-03,\n",
       "       -2.66708971e-03,  9.74296001e-05,  1.13586292e-03,  7.10431367e-03,\n",
       "       -7.01534111e-03,  5.68182440e-03,  1.85779232e-02, -2.28698725e-02,\n",
       "        1.49190855e-02, -7.38033686e-03])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag_features[hashtag_features['tag'] == '#tattoo']['features'].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "855b133e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24d24e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004191944"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender_df.at[68, 'features'] @ hashtag_features.at[68, 'features'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c722ff8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features       [0.0006249155, 0.0005484236, -0.0015651134, -0...\n",
       "id                                                            68\n",
       "tag                                                        #band\n",
       "dot_product                                             0.001747\n",
       "Name: 68, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag_features.loc[68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4418bcca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
