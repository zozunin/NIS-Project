{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":696},"executionInfo":{"elapsed":5495,"status":"ok","timestamp":1655303866584,"user":{"displayName":"Polina","userId":"07977093172725252944"},"user_tz":-180},"id":"nPeBKRDUP8S0","outputId":"c4702099-c80c-433b-8255-bf2aabe55d83"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting python-telegram-bot\n","  Downloading python_telegram_bot-13.12-py3-none-any.whl (511 kB)\n","\u001b[K     |████████████████████████████████| 511 kB 30.4 MB/s \n","\u001b[?25hCollecting tornado>=6.1\n","  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n","\u001b[K     |████████████████████████████████| 428 kB 69.4 MB/s \n","\u001b[?25hCollecting cachetools==4.2.2\n","  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n","Requirement already satisfied: pytz>=2018.6 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2022.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2022.5.18.1)\n","Collecting APScheduler==3.6.3\n","  Downloading APScheduler-3.6.3-py2.py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 7.3 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.15.0)\n","Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.5.1)\n","Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (57.4.0)\n","Installing collected packages: tornado, cachetools, APScheduler, python-telegram-bot\n","  Attempting uninstall: tornado\n","    Found existing installation: tornado 5.1.1\n","    Uninstalling tornado-5.1.1:\n","      Successfully uninstalled tornado-5.1.1\n","  Attempting uninstall: cachetools\n","    Found existing installation: cachetools 4.2.4\n","    Uninstalling cachetools-4.2.4:\n","      Successfully uninstalled cachetools-4.2.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\u001b[0m\n","Successfully installed APScheduler-3.6.3 cachetools-4.2.2 python-telegram-bot-13.12 tornado-6.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tornado"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install python-telegram-bot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XG0ZNqb4QHdJ"},"outputs":[],"source":["from telegram.ext import Updater, Filters, CommandHandler, MessageHandler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zEOw2nV04SCb"},"outputs":[],"source":["import os, time, sys, csv, io, time\n","import numpy as np\n","import pandas as pd\n","from PIL import Image, ImageFile\n","from google.colab.patches import cv2_imshow\n","from scipy.spatial import distance\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","from torchvision import transforms as trn\n","import torch.functional as F\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","from torch.utils.data import DataLoader, Dataset\n","import torch.optim as optim\n","import tqdm\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","ImageFile.LOAD_TRUNCATED_IMAGES = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jtWxorty7qgs"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import io\n","import tensorflow as tf\n","from tensorflow.keras.applications import MobileNetV2\n","from functools import reduce\n","import os\n","from scipy.spatial.distance import cosine\n","import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3275,"status":"ok","timestamp":1655312723859,"user":{"displayName":"Polina","userId":"07977093172725252944"},"user_tz":-180},"id":"aV2CtNRTq4u-","outputId":"bb8cb6c7-2492-4bea-eca9-0d5d058d0292"},"outputs":[{"data":{"text/plain":["img2vec(\n","  (linear1): Linear(in_features=2048, out_features=1024, bias=True)\n","  (linear2): Linear(in_features=1024, out_features=150, bias=True)\n",")"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["#model 1\n","\n","def img_centre_crop():\n","    # load the image transformer\n","    centre_crop = trn.Compose([\n","            trn.Resize((256,256)),\n","            trn.CenterCrop(224),\n","            trn.ToTensor(),\n","            trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","    return centre_crop\n","  \n","def read_tags(filename):\n","    threshold=0\n","\n","    read_data = []\n","    word_counter = {}\n","    file_path   = filename\n","    with open(file_path, 'r', encoding=\"utf-8\") as f:\n","        tmp = f.readlines()\n","        for content in tmp:\n","            content = content.strip('\\n').strip() \n","            test = content.strip().split()\n","            if len(test) > 1:\n","                read_data.append(test)\n","                for ele in test:\n","                    if ele not in word_counter.keys():\n","                        word_counter[ele] = 1\n","                    else:\n","                        word_counter[ele] += 1\n","    corpus = [k for k,v in word_counter.items() if v > threshold]\n","    word2idx = {k:v for v,k in enumerate(corpus, 1)}\n","    word2idx['UNK'] = 0\n","    idx2word = {v:k for v,k in enumerate(corpus, 1)}\n","    idx2word[0] = 'UNK'\n","    corpus = corpus+['UNK']\n","    return read_data, word_counter, corpus, word2idx, idx2word\n","\n","class img2vec(nn.Module):\n","    def __init__(self):\n","        super(img2vec, self).__init__()\n","        self.linear1 = nn.Linear(2048, 1024)\n","        self.linear2 = nn.Linear(1024, 150) \n","    \n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = self.linear2(x)\n","        return x\n","\n","def img_extractor():\n","    resnet50 = models.resnet50(num_classes=1000, pretrained=True)\n","    modules = list(resnet50.children())[:-1]\n","    resnet50 = nn.Sequential(*modules)\n","    return resnet50\n","\n","def top_k(y_pred, vec_matrix, k):\n","    tmp = cos_cdist(vec_matrix, y_pred)\n","    total_top_k = np.argsort(tmp)[:, :k]\n","    return total_top_k\n","\n","def cos_cdist(matrix, v):\n","   return distance.cdist(matrix, v, 'cosine').T\n","\n","def testing(imageID, img_extractor_model, img2vec, word2idx, word_vec_dict, vec_matrix):\n","\n","    crop = img_centre_crop()\n","    img = Image.open(imageID).convert('RGB') # открывашка изображения\n","    input_img = crop(img).unsqueeze(0).to(device)\n","\n","    tmp = []\n","    tmp += [imageID]\n","    with torch.no_grad():\n","        img_feat = img_extractor_model(input_img)\n","        pred = img2vec(img_feat.squeeze().unsqueeze(0)).detach().cpu()\n","        top_k_result = top_k(pred, vec_matrix, 10)[0]\n","        for ele in top_k_result:\n","            tmp += [idx2word[ele]]\n","        #print(tmp[1:]) #принтим теги\n","    return tmp\n","\n","npz_path = r'/content/drive/MyDrive/iad year 1/НИС/проект/модель1/wordvec_3_150.npz'\n","filename_ = \"/content/drive/MyDrive/iad year 1/НИС/проект/модель1/full_tag_list.txt\" # я не помню, зачем оно, но надо\n","\n","vec_matrix = np.load(npz_path)['wordvec']\n","word_vec_dict = {idx:vec for idx,vec in enumerate(vec_matrix)}\n","_, _, corpus, word2idx, idx2word = read_tags(filename_) # пофиксить путь\n","\n","img_extractor_model = img_extractor().to(device)\n","img2vec = img2vec().to(device)\n","\n","checkpoint = torch.load('/content/drive/MyDrive/iad year 1/НИС/проект/модель1/checkpoint.pth.tar', map_location=torch.device('cpu'))\n","img_extractor_model.load_state_dict(checkpoint['img_extractor_model_state_dict'])\n","img2vec.load_state_dict(checkpoint['img2vec_state_dict'])\n","\n","img_extractor_model.eval()\n","img2vec.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4647,"status":"ok","timestamp":1655312730349,"user":{"displayName":"Polina","userId":"07977093172725252944"},"user_tz":-180},"id":"0mGqEcVw6Vzs","outputId":"19e9cc21-aee5-4d8f-b746-dc1fe5df70de"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator PCA from version 0.24.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n","  UserWarning,\n"]}],"source":["#моделя 2\n","\n","def avg_hash_img(pth):\n","    with Image.open(pth) as img:\n","        img = img.resize((10,10), Image.ANTIALIAS).convert(\"1\") #shrink and reduce colors\n","        pixel_data = list(img.getdata())\n","        avg_pixel = sum(pixel_data)/len(pixel_data)\n","        bits = \"\".join(['1' if (px >= avg_pixel) else '0' for px in pixel_data])\n","        hex_representation = str(hex(int(bits, 2)))[2:][::-1].upper()\n","        return hex_representation\n","    \n","def use_pkl(mode, pkl_path, file_to_pkl = None):\n","    if not mode == 'rb' and not mode == 'ab' and not mode == 'wb':\n","        return None\n","    with open(pkl_path, mode) as f:\n","        if mode == 'rb':\n","            res = pickle.load(f)\n","            assert type(res) == np.ndarray or type(res) == pd.DataFrame\n","            res_add = []\n","            while True:\n","                try:\n","                    res_add.append(pickle.load(f))\n","                except EOFError:\n","                    break\n","            if type(res) == np.ndarray:\n","                return np.concatenate([res, *res_add], axis = 0)\n","            else:\n","                return pd.concat([res, *res_add], axis=0)\n","        else:\n","            pickle.dump(file_to_pkl, f) \n","\n","img_shape = (224, 224, 3)\n","\n","base_model = MobileNetV2(input_shape=img_shape, include_top=False, weights='imagenet')\n","\n","global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n","\n","neural_network = tf.keras.Sequential([\n","  base_model,\n","  global_average_layer,\n","])\n","\n","path_to_emb, path_to_hash ='/content/drive/MyDrive/iad year 1/НИС/проект/модель 2/embeddings.pkl', '/content/drive/MyDrive/iad year 1/НИС/проект/модель 2/hashtags.pkl'\n","recommender_df = use_pkl('rb', path_to_emb)\n","hashtag_features = use_pkl('rb', path_to_hash)\n","with open('/content/drive/MyDrive/iad year 1/НИС/проект/модель 2/pca.pkl', 'rb') as f:\n","    pca_model = pickle.load(f)\n","\n","def prepare_image(img_path, dims = (224, 224, 3), where='local'):\n","    height, width, _ = dims\n","    if not where == 'local':\n","        return\n","    img = tf.cast(tf.image.decode_image(tf.io.read_file(img_path)), tf.float32)\n","    img = (img/127.5) - 1 #normalize\n","    img = tf.image.resize(img, (height, width))\n","    if img.shape != dims: #for grayscale\n","        img = tf.concat([img, img, img], axis=2)\n","    return img\n","\n","\n","def extract_features(image, nn):\n","    image_np = image.numpy()\n","    images_np = np.expand_dims(image_np, axis=0)\n","    deep_features = nn.predict(images_np)[0]\n","    return deep_features\n","\n","def prepare_img(image_path, where='local'):\n","    prep_image = prepare_image(image_path, where='local')\n","    pic = pca_model.transform(extract_features(prep_image, neural_network).reshape(1,-1)).reshape(-1)\n","    return pic\n","\n","def find_neighbor_vectors(pic, k=5, recommender_df=recommender_df):\n","    \"\"\"Find image features (user vectors) for similar images.\"\"\"\n","    rdf = recommender_df.copy()\n","    rdf['dist'] = rdf['deep_features'].apply(lambda x: cosine(x, pic))\n","    rdf = rdf.sort_values(by='dist')\n","    return rdf.head(k)\n","\n","def generate_hashtags(pic, return_uf = False, min_recs = 10):\n","    fnv = find_neighbor_vectors(pic, k=5, recommender_df=recommender_df)\n","    # Find the average of the 5 user features found based on cosine similarity.\n","    features = []\n","    for item in fnv.features.values:\n","        features.append(item)\n","\n","    avg_features = np.mean(np.asarray(features), axis=0)\n","    \n","    # Add new column to the hashtag features which will be the dot product with the average image(user) features\n","    hashtag_features['dot_product'] = hashtag_features['features'].apply(lambda x: np.asarray(x).dot(avg_features))\n","\n","    # Find the 10 hashtags with the highest feature dot products\n","    final_recs = hashtag_features.sort_values(by='dot_product', ascending=False).head(min_recs)\n","    #print(final_recs)\n","    # Look up hashtags by their numeric IDs\n","    if not return_uf:\n","        avg_features = None\n","    return final_recs['tag'].to_list(), avg_features\n","\n","def get_results(path_to_pic, add_to_model = False, new_ind = None, path_to_emb = path_to_emb, path_to_hash = path_to_hash):\n","    \n","    \"\"\"Need to load embeddings.pkl to recommender_df, hashtags.pkl to hashtag_features for this to work\"\"\"\n","    \n","    im_hash = avg_hash_img(path_to_pic)\n","    \n","    in_db = sum(recommender_df['image_hash'].isin([im_hash]))\n","    \n","    if in_db:\n","        \n","        target_pic = recommender_df[recommender_df['image_hash'] == im_hash]\n","        \n","        embedding = target_pic['deep_features'].values[0]\n","    \n","    else:\n","        \n","        embedding = prepare_img(path_to_pic)\n","        \n","    tags, user_feat = generate_hashtags(embedding, return_uf = add_to_model)\n","    \n","    if in_db: new_ind = target_pic.index[0]\n","    \n","    elif add_to_model:\n","        \n","        new_ind = max(recommender_df.index) + 1\n","        \n","        props = {'image_hash' : im_hash, 'hashtags' : [tags], \n","                               'deep_features' : [embedding], 'features' : [user_feat]}\n","        \n","        to_pkl = pd.DataFrame(props, index = [new_ind])\n","        \n","        for k,v in props.items():\n","            \n","            recommender_df.loc[new_ind,k] = v[0]\n","            \n","        use_pkl('ab', path_to_emb, file_to_pkl = to_pkl)\n","        \n","    return tags, new_ind #recommended tags & index of the newly added picture - necessary for uploading new hashtags\n","\n","def add_hashtags_to_db(picture_df_index, str_of_hashtags):\n","    \n","    global hashtag_features\n","    \n","    assert picture_df_index in recommender_df.index\n","    \n","    str_of_hashtags = list(set(str_of_hashtags))\n","    \n","    A = [fv for fv in recommender_df['features']]\n","    \n","    props = {'features' : [], 'id' : [], 'tag' : []}\n","    \n","    curr_index = max(hashtag_features.index) + 1\n","    \n","    for hashtag in str_of_hashtags:\n","        \n","        hashtag = '#' + hashtag\n","        \n","        h_index = hashtag_features[hashtag_features['tag'] == hashtag]\n","        \n","        #pics_for_hashtag = h_index['image_id'].values\n","        \n","        if len(h_index) > 0: #hashtag already in database\n","            \n","            h_index = h_index.index[0]\n","            \n","        else:\n","            \n","            h_index = None\n","        \n","        b = []\n","        \n","        for index in recommender_df.index:\n","            \n","            b_i = 0\n","                \n","            if index == picture_df_index:\n","                \n","                b_i = 1\n","\n","            elif h_index:\n","                \n","                b_i = recommender_df.at[index, 'features'] @ hashtag_features.at[h_index, 'features'].T\n","                \n","            b.append(b_i)\n","            \n","        hashtag_vector = np.linalg.lstsq(A,b)[0].T\n","        \n","        if h_index:\n","            \n","            hashtag_features.at[h_index, 'features'] = hashtag_vector.T\n","            \n","        else:\n","        \n","            props['features'].append(hashtag_vector)\n","            props['tag'].append(hashtag)\n","            props['id'].append(curr_index)\n","            curr_index += 1\n","        \n","    if props['id']:\n","        to_pkl = pd.DataFrame(props, index = props['id'])\n","\n","        hashtag_features = pd.concat([hashtag_features, to_pkl])\n","\n","        use_pkl('ab', path_to_hash, file_to_pkl = to_pkl)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u0DzbTei8xN5"},"outputs":[],"source":["model = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AfcEvBSSQUjW"},"outputs":[],"source":["def start_(updater, context):\n","  updater.message.reply_text('''tag4pic бот приветствует тебя! Пришли изображение, чтобы я подобрал к нему хештеги!\\n\\nЯ храню в себе две модели. Чтобы выбрать любую из них, пришли 1 или 2.\\n\\nЧтобы увидеть работающую модель, вызови команду /model''')\n","\n","def help_(updater, context):\n","  updater.message.reply_text('''Для того, чтобы бот заработал, необходимо прислать изображение.\\n\\nЧтобы выбрать модель, пришли 1 или 2 (цифра соответствует своей модели).\\n\\nЧтобы увидеть работающую модель, вызови команду /model''')\n","\n","def model_(updater, context):\n","  model\n","  updater.message.reply_text('Сейчас работает модель: {}'.format(model))\n","\n","def message_(updater, context):\n","  global model\n","  msg = updater.message.text\n","  if msg == '1':\n","    model = 1\n","    updater.message.reply_text('Успешно поменял модель на 1!')\n","  elif msg == '2':\n","    model = 2\n","    updater.message.reply_text('Успешно поменял модель на 2!\\n\\nТакже ты можешь добавить свой хештег к изображению, которое ты мне присылаешь, чтобы модель запомнила твой выбор и лучше предсказывала хештеги! Для этого введи хештеги с # через пробел.')\n","  elif model == 2 and msg[0] == '#':\n","    usr_hashtags = msg.lower().split()\n","    hashtags = [i if i[0] == '#' else '#' + i for i in usr_hashtags]\n","    recom_tags, new_img_index = get_results('img.jpg', add_to_model = True)\n","    add_hashtags_to_db(new_img_index, hashtags)\n","    updater.message.reply_text('Спасибо! Ты только что улучшил мою производительность.\\n\\nС уважением, Модель 2.')\n","  elif msg != '1' and msg != '2':\n","    updater.message.reply_text('Я понимаю только изображения :(\\n\\nЕсли ты хочешь поменять модель, пришли 1 или 2.\\n\\nЕсли ты хочешь ввести хештег, начни сообщение с #.')\n","\n","def image_(updater, context):\n","  photo = updater.message.photo[-1].get_file()\n","  photo.download(\"img.jpg\")\n","  if model == 1:\n","    pred = testing(\"img.jpg\", img_extractor_model, img2vec, word2idx, word_vec_dict, vec_matrix)\n","    result_text = '\\n#'.join(pred[1:])\n","    give_result = 'Возможные хештеги для твоего изображения:\\n\\n#' + result_text\n","  if model == 2:\n","    recom_tags, new_img_index = get_results('img.jpg', add_to_model = True)\n","    result_text = '\\n'.join(recom_tags)\n","    give_result = 'Возможные хештеги для твоего изображения:\\n\\n' + result_text\n","  updater.message.reply_text(give_result)"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJeFjpzKQ0bV","executionInfo":{"status":"ok","timestamp":1655319396842,"user_tz":-180,"elapsed":6803,"user":{"displayName":"Polina","userId":"07977093172725252944"}},"outputId":"d9897e42-58cf-40b4-a3ae-16cacc5bd541"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:184: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n","To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:184: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n","To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:184: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n","To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:184: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n","To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:184: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n","To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:184: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n","To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:184: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n","To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"]}],"source":["updater = Updater('5426775163:AAFlSiCNTNtS4fIE5zk7o50MIhZWZRsGqfU')\n","dispatcher = updater.dispatcher\n","\n","dispatcher.add_handler(CommandHandler(\"start\", start_))\n","dispatcher.add_handler(CommandHandler(\"help\", help_))\n","dispatcher.add_handler(CommandHandler(\"model\", model_))\n","dispatcher.add_handler(MessageHandler(Filters.text, message_))\n","dispatcher.add_handler(MessageHandler(Filters.photo, image_))\n","\n","updater.start_polling()\n","updater.idle()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PEE8De5wSVgJ"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"bot.py","provenance":[],"mount_file_id":"1xyYoek9CBP5knm21gUB-sq3-oETpdSu3","authorship_tag":"ABX9TyNQuRAn+UiYc661/QbtAGTD"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}